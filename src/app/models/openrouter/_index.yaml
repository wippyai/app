version: "1.0"
namespace: app.models.openrouter

entries:
  # app.models.openrouter:api_key
  - name: api_key
    kind: env.variable
    meta:
      comment: OpenRouter API key for authentication
      icon: tabler:key
    storage: app.env:router
    variable: OPENROUTER_API_KEY

  # app.models.openrouter:claude-3-5-haiku
  - name: claude-3-5-haiku
    kind: registry.entry
    meta:
      name: claude-3-5-haiku
      type: llm.model
      title: Claude 3.5 Haiku
      comment: Updated fast model with improved coding and reasoning capabilities while maintaining speed and cost efficiency
      capabilities:
        - tool_use
        - vision
        - generate
        - structured_output
        - coding
      class:
        - fast
        - cost-effective
        - coding
      priority: 75
    max_tokens: 200000
    output_tokens: 8192
    pricing:
      input: 1
      output: 5
    providers:
      - id: app.models.openrouter:provider
        provider_model: anthropic/claude-3.5-haiku

  # app.models.openrouter:claude-3-5-sonnet
  - name: claude-3-5-sonnet
    kind: registry.entry
    meta:
      name: claude-3-5-sonnet
      type: llm.model
      title: Claude 3.5 Sonnet
      comment: Balanced model with strong performance in coding, analysis, and general tasks
      capabilities:
        - tool_use
        - vision
        - generate
        - structured_output
        - coding
      class:
        - balanced
        - coding
        - default
      priority: 85
    max_tokens: 200000
    output_tokens: 8192
    pricing:
      input: 3
      output: 15
    providers:
      - id: app.models.openrouter:provider
        provider_model: anthropic/claude-3.5-sonnet

  # app.models.openrouter:claude-4-5-haiku
  - name: claude-4-5-haiku
    kind: registry.entry
    meta:
      name: claude-4-5-haiku
      type: llm.model
      title: Claude 4.5 Haiku
      comment: Updated fast model with improved coding and reasoning capabilities while maintaining speed and cost efficiency
      capabilities:
        - tool_use
        - vision
        - generate
        - structured_output
        - coding
      class:
        - fast
        - cost-effective
        - coding
      priority: 75
    max_tokens: 200000
    output_tokens: 8192
    pricing:
      input: 1
      output: 5
    providers:
      - id: app.models.openrouter:provider
        provider_model: anthropic/claude-haiku-4.5

  # app.models.openrouter:claude-4-5-sonnet
  - name: claude-4-5-sonnet
    kind: registry.entry
    meta:
      name: claude-4-5-sonnet
      type: llm.model
      title: Claude 4.5 Sonnet
      comment: Anthropic's flagship Claude 4 model with advanced reasoning, vision, and thinking capabilities
      capabilities:
        - tool_use
        - vision
        - thinking
        - caching
        - generate
        - structured_output
      class:
        - coding
        - flagship
      priority: 105
    max_tokens: 200000
    output_tokens: 64000
    pricing:
      input: 3
      output: 15
    providers:
      - id: app.models.openrouter:provider
        options:
          reasoning_model_request: true
        provider_model: anthropic/claude-sonnet-4.5

  # app.models.openrouter:claude-4-sonnet
  - name: claude-4-sonnet
    kind: registry.entry
    meta:
      name: claude-4-sonnet
      type: llm.model
      title: Claude 4 Sonnet
      comment: Anthropic's flagship Claude 4 model with advanced reasoning, vision, and thinking capabilities
      capabilities:
        - tool_use
        - vision
        - thinking
        - caching
        - generate
        - structured_output
      class:
        - coding
        - flagship
      priority: 105
    max_tokens: 200000
    output_tokens: 64000
    pricing:
      input: 3
      output: 15
    providers:
      - id: app.models.openrouter:provider
        options:
          reasoning_model_request: true
        provider_model: anthropic/claude-sonnet-4

  # app.models.openrouter:claude-opus-4
  - name: claude-opus-4
    kind: registry.entry
    meta:
      name: claude-opus-4
      type: llm.model
      title: Claude Opus 4
      comment: Most advanced model with state-of-art performance in complex agent workflows, autonomous research, and enterprise tasks
      capabilities:
        - tool_use
        - vision
        - thinking
        - generate
        - structured_output
        - coding
        - reasoning
        - agentic
      class:
        - flagship
        - reasoning
        - enterprise
        - agentic
      priority: 110
    max_tokens: 200000
    output_tokens: 64000
    pricing:
      input: 15
      output: 75
    providers:
      - id: app.models.openrouter:provider
        options:
          reasoning_model_request: true
        provider_model: anthropic/claude-opus-4

  # app.models.openrouter:deepseek-chat-v3-0324
  - name: deepseek-chat-v3-0324
    kind: registry.entry
    meta:
      name: deepseek-chat-v3-0324
      type: llm.model
      title: DeepSeek V3 0324
      comment: 685B parameter mixture-of-experts model with strong performance across diverse tasks and 131K context
      capabilities:
        - tool_use
        - generate
        - structured_output
        - coding
      class:
        - cost-effective
        - coding
        - flagship
      priority: 95
    max_tokens: 131072
    output_tokens: 32768
    pricing:
      input: 0.2
      output: 0.8
    providers:
      - id: app.models.openrouter:provider
        provider_model: deepseek/deepseek-chat-v3-0324

  # app.models.openrouter:deepseek-r1
  - name: deepseek-r1
    kind: registry.entry
    meta:
      name: deepseek-r1
      type: llm.model
      title: DeepSeek R1
      comment: 671B parameter open source reasoning model with performance comparable to OpenAI o1, MIT licensed, chain-of-thought reasoning
      capabilities:
        - tool_use
        - thinking
        - generate
        - structured_output
        - reasoning
      class:
        - reasoning
        - open-source
        - flagship
      priority: 110
    max_tokens: 163840
    output_tokens: 32768
    pricing:
      input: 0.27
      output: 1.35
    providers:
      - id: app.models.openrouter:provider
        provider_model: deepseek/deepseek-r1

  # app.models.openrouter:gemini-2-5-flash
  - name: gemini-2-5-flash
    kind: registry.entry
    meta:
      name: gemini-2-5-flash
      type: llm.model
      title: Gemini 2.5 Flash
      comment: Google's state-of-the-art workhorse model with advanced reasoning, coding, mathematics, and built-in thinking capabilities
      capabilities:
        - tool_use
        - vision
        - thinking
        - generate
        - structured_output
      class:
        - balanced
        - reasoning
        - coding
      priority: 90
    max_tokens: 1.048576e+06
    output_tokens: 32768
    pricing:
      input: 0.15
      output: 0.6
    providers:
      - id: app.models.openrouter:provider
        provider_model: google/gemini-2.5-flash

  # app.models.openrouter:gemini-2-5-flash-lite
  - name: gemini-2-5-flash-lite
    kind: registry.entry
    meta:
      name: gemini-2-5-flash-lite
      type: llm.model
      title: Gemini 2.5 Flash Lite
      comment: Lightweight reasoning model optimized for ultra-low latency and cost efficiency with optional thinking mode
      capabilities:
        - tool_use
        - vision
        - thinking
        - generate
        - structured_output
      class:
        - fast
        - cost-effective
        - reasoning
      priority: 80
    max_tokens: 1.048576e+06
    output_tokens: 32768
    pricing:
      input: 0.1
      output: 0.4
    providers:
      - id: app.models.openrouter:provider
        provider_model: google/gemini-2.5-flash-lite

  # app.models.openrouter:gemini-2-5-pro
  - name: gemini-2-5-pro
    kind: registry.entry
    meta:
      name: gemini-2-5-pro
      type: llm.model
      title: Gemini 2.5 Pro
      comment: Google's latest flagship model with 1M context window and multimodal capabilities
      capabilities:
        - tool_use
        - vision
        - generate
        - structured_output
      class:
        - flagship
        - multimodal
        - long-context
      priority: 95
    max_tokens: 1e+06
    output_tokens: 32768
    pricing:
      input: 2.5
      output: 10
    providers:
      - id: app.models.openrouter:provider
        provider_model: google/gemini-2.5-pro

  # app.models.openrouter:glm-4-6
  - name: glm-4-6
    kind: registry.entry
    meta:
      name: glm-4-6
      type: llm.model
      title: GLM 4.6
      comment: Enhanced model with comprehensive improvements in coding, long-context processing, reasoning, and agentic applications
      capabilities:
        - tool_use
        - thinking
        - generate
        - structured_output
        - coding
        - reasoning
      class:
        - coding
        - reasoning
        - balanced
      priority: 88
    max_tokens: 200000
    output_tokens: 32768
    pricing:
      input: 0.6
      output: 2.2
    providers:
      - id: app.models.openrouter:provider
        provider_model: z-ai/glm-4.6

  # app.models.openrouter:grok-3
  - name: grok-3
    kind: registry.entry
    meta:
      name: grok-3
      type: llm.model
      title: Grok 3
      comment: xAI's flagship model excelling at enterprise use cases like data extraction, coding, and text summarization
      capabilities:
        - tool_use
        - thinking
        - generate
        - structured_output
      class:
        - enterprise
        - coding
        - default
      priority: 95
    max_tokens: 131072
    output_tokens: 32768
    pricing:
      input: 2.5
      output: 10
    providers:
      - id: app.models.openrouter:provider
        provider_model: x-ai/grok-3

  # app.models.openrouter:grok-3-mini
  - name: grok-3-mini
    kind: registry.entry
    meta:
      name: grok-3-mini
      type: llm.model
      title: Grok 3 Mini
      comment: Lightweight thinking model that contemplates before responding, optimized for reasoning-heavy tasks
      capabilities:
        - thinking
        - generate
        - structured_output
      class:
        - reasoning
        - mini
        - cost-effective
      priority: 85
    max_tokens: 131072
    output_tokens: 16384
    pricing:
      input: 1.1
      output: 4.4
    providers:
      - id: app.models.openrouter:provider
        provider_model: x-ai/grok-3-mini

  # app.models.openrouter:grok-4
  - name: grok-4
    kind: registry.entry
    meta:
      name: grok-4
      type: llm.model
      title: Grok 4
      comment: xAI's latest reasoning model with 256k context window, parallel tool calling, and structured outputs
      capabilities:
        - tool_use
        - vision
        - thinking
        - generate
        - structured_output
      class:
        - reasoning
        - flagship
      priority: 100
    max_tokens: 256000
    output_tokens: 32768
    pricing:
      input: 10
      output: 40
    providers:
      - id: app.models.openrouter:provider
        provider_model: x-ai/grok-4

  # app.models.openrouter:grok-4-fast
  - name: grok-4-fast
    kind: registry.entry
    meta:
      name: grok-4-fast
      type: llm.model
      title: Grok 4 Fast
      comment: xAI's latest multimodal model with SOTA cost-efficiency, 2M token context, and optional reasoning mode
      capabilities:
        - tool_use
        - vision
        - thinking
        - generate
        - structured_output
      class:
        - fast
        - cost-effective
        - multimodal
      priority: 90
    max_tokens: 2e+06
    output_tokens: 32768
    pricing:
      input: 0.2
      output: 0.5
    providers:
      - id: app.models.openrouter:provider
        provider_model: x-ai/grok-4-fast

  # app.models.openrouter:grok-code-fast-1
  - name: grok-code-fast-1
    kind: registry.entry
    meta:
      name: grok-code-fast-1
      type: llm.model
      title: Grok Code Fast 1
      comment: xAI's specialized fast coding model optimized for rapid code generation and programming tasks
      capabilities:
        - tool_use
        - generate
        - structured_output
        - coding
      class:
        - coding
        - fast
        - specialized
      priority: 90
    max_tokens: 131072
    output_tokens: 32768
    pricing:
      input: 1.5
      output: 6
    providers:
      - id: app.models.openrouter:provider
        provider_model: x-ai/grok-code-fast-1

  # app.models.openrouter:kimi-k2
  - name: kimi-k2
    kind: registry.entry
    meta:
      name: kimi-k2
      type: llm.model
      title: Kimi K2
      comment: 1T parameter MoE model (32B active), SOTA open source model optimized for agentic capabilities and tool use, 65.8% SWE-bench
      capabilities:
        - tool_use
        - generate
        - structured_output
        - coding
        - agentic
      class:
        - open-source
        - flagship
        - coding
        - agentic
      priority: 106
    max_tokens: 128000
    output_tokens: 32768
    pricing:
      input: 0.14
      output: 2.49
    providers:
      - id: app.models.openrouter:provider
        provider_model: moonshotai/kimi-k2

  # app.models.openrouter:provider
  - name: provider
    kind: registry.entry
    meta:
      name: openrouter
      type: llm.provider
      title: OpenRouter
      comment: OpenRouter API provider for accessing multiple LLM models
      tags:
        - llm
        - provider
        - openrouter
    driver:
      id: wippy.llm.openai:driver
      options:
        api_key_env: OPENROUTER_API_KEY
        base_url: https://openrouter.ai/api/v1
        headers:
          HTTP-Referer: https://wippy.ai
          X-Title: Wippy
        organization: ""
        timeout: "1200"

  # app.models.openrouter:qwen3-235b-a22b-2507
  - name: qwen3-235b-a22b-2507
    kind: registry.entry
    meta:
      name: qwen3-235b-a22b-2507
      type: llm.model
      title: Qwen3 235B A22B 2507
      comment: 235B parameter MoE model with 22B active parameters, enhanced reasoning, instruction-following, and multilingual support
      capabilities:
        - tool_use
        - thinking
        - generate
        - structured_output
        - coding
      class:
        - flagship
        - reasoning
        - multilingual
      priority: 92
    max_tokens: 131072
    output_tokens: 32768
    pricing:
      input: 0.6
      output: 2.5
    providers:
      - id: app.models.openrouter:provider
        provider_model: qwen/qwen3-235b-a22b-2507

  # app.models.openrouter:qwen3-coder
  - name: qwen3-coder
    kind: registry.entry
    meta:
      name: qwen3-coder
      type: llm.model
      title: Qwen3 Coder
      comment: 480B parameter MoE code model with 35B active parameters, optimized for agentic coding, tool use, and repository-scale understanding
      capabilities:
        - tool_use
        - generate
        - structured_output
        - coding
        - agentic
      class:
        - coding
        - agentic
        - specialized
      priority: 94
    max_tokens: 256000
    output_tokens: 32768
    pricing:
      input: 0.35
      output: 1.4
    providers:
      - id: app.models.openrouter:provider
        provider_model: qwen/qwen3-coder
